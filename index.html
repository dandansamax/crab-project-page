<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents">
  <meta name="keywords" content="Autonomous Agent, Benchmark, GUI automation, Multimodal Language Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">CRAB: Cross-environment Agent Benchmark for Multimodal Language
              Model Agents</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://dandansamax.github.io/">Tianqi Xu</a><sup>1,2*</sup>,
              </span>
              <span class="author-block">
                <a href="TODO">Linyao Chen</a><sup>3*</sup>,
              </span>
              <span class="author-block">
                <a href="https://github.com/jaywu109">Dai-Jie Wu</a><sup>1*</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/yanjun-c-65166b190/">Yanjun Chen</a><sup>4*</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/zechengzhang/">Zecheng Zhang</a>,
              </span>
              <span class="author-block">
                <a href="TODO">Xiang Yao</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://zhiqiangxie.com/">Zhiqiang Xie</a><sup>5</sup>
              </span>
              <span class="author-block">
                <a href="https://aeroastro.mit.edu/realm/team/yongchao-chen/">Yongchao Chen</a><sup>6</sup>
              </span>
              <span class="author-block">
                <a href="http://lsl.zone/">Shilong Liu</a><sup>7</sup>
              </span>
              <span class="author-block">
                <a href="TODO">Bochen Qian</a><sup>8</sup>
              </span>
              <span class="author-block">
                <a href="https://www.robots.ox.ac.uk/~phst/">Philip Torr</a><sup>9</sup>
              </span>
              <span class="author-block">
                <a href="https://www.bernardghanem.com/">Bernard Ghanem</a><sup>1†</sup>
              </span>
              <span class="author-block">
                <a href="https://ghli.org/">Guohao Li</a><sup>2,9†</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>KAUST,</span>
              <span class="author-block"><sup>2</sup>Eigent.AI,</span>
              <span class="author-block"><sup>3</sup>UTokyo,</span>
              <span class="author-block"><sup>4</sup>CMU,</span>
              <span class="author-block"><sup>5</sup>Stanford,</span>
              <span class="author-block"><sup>6</sup>Harvard,</span>
              <span class="author-block"><sup>7</sup>Tsinghua,</span>
              <span class="author-block"><sup>8</sup>SUSTech,</span>
              <span class="author-block"><sup>9</sup>Oxford</span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>*</sup>Equal Contribution</span>
              <span class="author-block"><sup>†</sup>Corresponding Author</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2407.01511" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2407.01511" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/camel-ai/crab" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span> -->
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
          free-viewpoint
          portraits.
        </h2>
      </div>
    </div>
  </section> -->
  <!-- 

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/steve.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chair-tp.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shiba.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fullbody.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/blueshirt.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-mask">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/mask.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-coffee">
            <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/coffee.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toby">
            <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/toby2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section> -->


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Introduction Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The development of autonomous agents increasingly relies on Multimodal Language Models (MLMs) to perform
              tasks described in natural language with GUI environments, such as websites, desktop computers, or mobile
              phones. Existing benchmarks for MLM agents in interactive environments are limited by their focus on a
              single environment, lack of detailed and generalized evaluation methods, and the complexities of
              constructing tasks and evaluators. To overcome these limitations, we introduce Crab, the first agent
              benchmark framework designed to support cross-environment tasks, incorporating a graph-based fine-grained
              evaluation method and an efficient mechanism for task and evaluator construction. Our framework supports
              multiple devices and can be easily extended to any environment with a Python interface. Leveraging Crab,
              we developed a cross-platform Crab Benchmark-v0 comprising 100 tasks in computer desktop and mobile phone
              environments. We evaluated four advanced MLMs using different single and multi-agent system configurations
              on this benchmark. The experimental results demonstrate that the single agent with GPT-4o achieves the
              best completion ratio of 35.26%. All framework code, agent code, and task datasets are publicly available
              at https://github.com/camel-ai/crab.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Demo1 -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Demo Videos</h2>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content">
            <p>
              Open "Slack" in Ubuntu, navigate to "multi-modal-benchmark" channel, summarize the last two messages, then
              use "Messages" app in android phone to send the to the first contact in the list.
            </p>
            <p class="has-text-centered" style="color:#8A8B8C;">
              Settings: OpenAI GPT-4o + Multi-agent by Functionality
            </p>
            <video id="dollyzoom" controls muted playsinline height="100%">
              <source src="./static/videos/demo1_slack_to_message.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <!--/ Demo1 -->

      <hr>

      <!-- Demo2 -->
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content">
            <p>
              Open "Tasks" app on Android, check the first incomplete task, then perform the task according to its
              description
            </p>
            <p class="has-text-centered" style="color:#8A8B8C;">
              Settings: OpenAI GPT-4o + Multi-agent by Functionality
            </p>
            <video id="dollyzoom" controls muted playsinline height="100%">
              <source src="./static/videos/demo2_task_to_settings.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <!--/ Demo2 -->

      <hr>

      <!-- Demo3 -->
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content">
            <p>
              Open "Calendar" app on Android, summarize all schedules today. Then, in Ubuntu, create a markdown file at
              "/home/crab/assets/plan.md" with each event as a checkbox bullet point using Terminal and Vim.
            </p>
            <p class="has-text-centered" style="color:#8A8B8C;">
              Settings: OpenAI GPT-4o + Single Agent
            </p>
            <video id="dollyzoom" controls muted playsinline height="100%">
              <source src="./static/videos/demo3_calendar_to_vim.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <!--/ Demo3 -->

      <div class="content">
        <p class="is-centered" style="color:#8A8B8C;">
          Demo videos are edited for a better viewing experience. In actual execution, there are tens of seconds of
          waiting time between each step.
        </p>
      </div>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">

      <!-- Concurrent Work. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered">Related Works</h2>

          <div class="content has-text-justified">
            <p>
              We compare CRAB with existing GUI agents and benchmarks.
            </p>

            <img src="./static/images/crab-compare.png">

            <p>The columns detail key features of each framework:</p>
            <ul>
              <li><strong>Interactive Environment</strong> indicates the presence of either interactive environments or
                static datasets.</li>
              <li><strong>Multimodal Observation</strong> specifies the availability of vision-based observations (e.g.
                screenshots).</li>
              <li><strong>Cross-platform</strong> denotes support for multiple operating systems or platforms.</li>
              <li><strong>Evaluation</strong> describes the evaluation metrics, categorized as:
                <ul>
                  <li><strong>Goal-based:</strong> checking environment state according solely on the final goal.</li>
                  <li><strong>Trajectory-based:</strong> comparing agent action trajectory with a gold actions sequence.
                  </li>
                  <li><strong>Multiple:</strong> varied across tasks.</li>
                  <li><strong>Graph-based:</strong> a DAG with each node as an intermediate checkpoint.</li>
                </ul>
              </li>
              <li><strong>Task Construction</strong> shows the task construction method, including:
                <ul>
                  <li><strong>Handmade:</strong> handcrafted by human.</li>
                  <li><strong>LLM-inspired:</strong> using LLM to generate task drafts but still verified and annotated
                    by human.</li>
                  <li><strong>Template:</strong> generated by filling in the blanks in task templates.</li>
                  <li><strong>Sub-task Composition:</strong> composing multiple sub-tasks to construct tasks and
                    evaluators.</li>
                </ul>
              </li>
            </ul>

          </div>
        </div>
      </div>
      <!--/ Concurrent Work. -->

    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{xu2024crab,
      title={CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents}, 
      author={Tianqi Xu and Linyao Chen and Dai-Jie Wu and Yanjun Chen and Zecheng Zhang and Xiang Yao and Zhiqiang Xie and Yongchao Chen and Shilong Liu and Bochen Qian and Philip Torr and Bernard Ghanem and Guohao Li},
      year={2024},
      eprint={2407.01511},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.01511}, 
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="./static/videos/nerfies_paper.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>